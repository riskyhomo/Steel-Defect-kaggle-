{
  "cells": [
    {
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'severstal-steel-defect-detection:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F14241%2F862020%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240206%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240206T154842Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4149fac6111b02c9e4b992b31db1811e08aea81e158229ee9ab75deff0484848390ee4077cfbde3c4a96a3108b21a2d7db5f2d91552b8a1db75769fa16d77f6fb4ab6e53580f16cbde2942bfbb874754100f04ce5afae0fafc8ed58df5656d771e26baba294f9b7f5adbfff3de4782f1668160a28a540181af86dbd459779a003aa12fbfd5821cc7d3d33ca105fc68c59a71883f810cacfbcc74faf68fe701d3daeab213c29f6bd3ed636d9bdf79d119d84b2b18d8e044e1d1eb1dc77c658cf2f8b5ba199964feb948d0be2cb63603182525d4b538a1eae817b6abb8ed65e280ef2f8fcc4b368ca7d3fbba1360befc172bce4cbe1af2e249d495718dc9d4886f'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "0uR6hq7zG45a"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "rfdElap8G45h"
      },
      "cell_type": "markdown",
      "source": [
        "#### Imports"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "au7TUkCTG45h"
      },
      "cell_type": "code",
      "source": [
        "# some basic imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "cNtV3rTQG45i"
      },
      "cell_type": "code",
      "source": [
        "# imports for building the network\n",
        "import tensorflow as tf\n",
        "from tensorflow import reduce_sum\n",
        "from tensorflow.keras.backend import pow\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D, Concatenate, Add, Flatten\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g-anZBV2G45i"
      },
      "cell_type": "markdown",
      "source": [
        "#### Configurations"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "D075VoK6G45i"
      },
      "cell_type": "code",
      "source": [
        "# Kernel Configurations\n",
        "make_submission = False # used to turn off lengthy model analysis so a submission version doesn't run into memory error\n",
        "load_pretrained_model = True # load a pre-trained model\n",
        "save_model = True # save the model after training\n",
        "train_dir = '../input/severstal-steel-defect-detection/' # directory of training images\n",
        "pretrained_model_path = '../input/severstal-pretrained-model/ResUNetSteel_z.h5' # path of pretrained model\n",
        "model_save_path = './ResUNetSteel_w800e50_z.h5' # path of model to save\n",
        "train_image_dir = os.path.join(train_dir, 'train_images') #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "lJ76Y0ztG45j"
      },
      "cell_type": "code",
      "source": [
        "# network configuration parameters\n",
        "# original image is 1600x256, so we will resize it\n",
        "img_w = 800 # resized weidth\n",
        "img_h = 256 # resized height\n",
        "batch_size = 12\n",
        "epochs = 25\n",
        "# batch size for training unet\n",
        "k_size = 3 # kernel size 3x3\n",
        "val_size = .20 # split of training set between train and validation set\n",
        "# we will repeat the images with lower samples to make the training process more fair\n",
        "repeat = False\n",
        "# only valid if repeat is True\n",
        "class_1_repeat = 1 # repeat class 1 examples x times\n",
        "class_2_repeat = 1\n",
        "class_3_repeat = 1\n",
        "class_4_repeat = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YYzaYIuyG45j"
      },
      "cell_type": "markdown",
      "source": [
        "#### Load & Transform train.csv"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "wgBFlTJLG45k"
      },
      "cell_type": "code",
      "source": [
        "# load full data and label no mask as -1\n",
        "train_df = pd.read_csv(os.path.join(train_dir, 'train.csv')).fillna(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "4jKpGqO0G45k"
      },
      "cell_type": "code",
      "source": [
        "# image id and class id are two seperate entities and it makes it easier to split them up in two columns\n",
        "train_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
        "train_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\n",
        "# lets create a dict with class id and encoded pixels and group all the defaults per image\n",
        "train_df['ClassId_EncodedPixels'] = train_df.apply(lambda row: (row['ClassId'], row['EncodedPixels']), axis = 1)\n",
        "grouped_EncodedPixels = train_df.groupby('ImageId')['ClassId_EncodedPixels'].apply(list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dolfI77gG45k"
      },
      "cell_type": "markdown",
      "source": [
        "#### Utility Functions for RLE Encoding & Decoding"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "CaIMqN5NG45k"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def rle_to_mask(rle_string,height,width):\n",
        "    '''\n",
        "    convert RLE(run length encoding) string to numpy array\n",
        "\n",
        "    Parameters:\n",
        "    rleString (str): Description of arg1\n",
        "    height (int): height of the mask\n",
        "    width (int): width of the mask\n",
        "\n",
        "    Returns:\n",
        "    numpy.array: numpy array of the mask\n",
        "    '''\n",
        "    rows, cols = height, width\n",
        "    if rle_string == -1:\n",
        "        return np.zeros((height, width))\n",
        "    else:\n",
        "        rleNumbers = [int(numstring) for numstring in rle_string.split(' ')]\n",
        "        rlePairs = np.array(rleNumbers).reshape(-1,2)\n",
        "        img = np.zeros(rows*cols,dtype=np.uint8)\n",
        "        for index,length in rlePairs:\n",
        "            index -= 1\n",
        "            img[index:index+length] = 255\n",
        "        img = img.reshape(cols,rows)\n",
        "        img = img.T\n",
        "        return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "D1Y7w8FVG45k"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def mask_to_rle(mask):\n",
        "    '''\n",
        "    Convert a mask into RLE\n",
        "\n",
        "    Parameters:\n",
        "    mask (numpy.array): binary mask of numpy array where 1 - mask, 0 - background\n",
        "\n",
        "    Returns:\n",
        "    sring: run length encoding\n",
        "    '''\n",
        "    pixels= mask.T.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "pePD4aNgG45l"
      },
      "cell_type": "code",
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, list_ids, labels, image_dir, batch_size=32,\n",
        "                 img_h=256, img_w=512, shuffle=True):\n",
        "\n",
        "        self.list_ids = list_ids\n",
        "        self.labels = labels\n",
        "        self.image_dir = image_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.img_h = img_h\n",
        "        self.img_w = img_w\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_ids)) / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'generate one batch of data'\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        # get list of IDs\n",
        "        list_ids_temp = [self.list_ids[k] for k in indexes]\n",
        "        # generate data\n",
        "        X, y = self.__data_generation(list_ids_temp)\n",
        "        # return data\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'update ended after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_ids))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_ids_temp):\n",
        "        'generate data containing batch_size samples'\n",
        "        X = np.empty((self.batch_size, self.img_h, self.img_w, 1))\n",
        "        y = np.empty((self.batch_size, self.img_h, self.img_w, 4))\n",
        "\n",
        "        for idx, id in enumerate(list_ids_temp):\n",
        "            file_path =  os.path.join(self.image_dir, id)\n",
        "            image = cv2.imread(file_path, 0)\n",
        "            image_resized = cv2.resize(image, (self.img_w, self.img_h))\n",
        "            image_resized = np.array(image_resized, dtype=np.float64)\n",
        "            # standardization of the image\n",
        "            image_resized -= image_resized.mean()\n",
        "            image_resized /= image_resized.std()\n",
        "\n",
        "            mask = np.empty((img_h, img_w, 4))\n",
        "\n",
        "            for idm, image_class in enumerate(['1','2','3','4']):\n",
        "                rle = self.labels.get(id + '_' + image_class)\n",
        "                # if there is no mask create empty mask\n",
        "                if rle is None:\n",
        "                    class_mask = np.zeros((1600, 256))\n",
        "                else:\n",
        "                    class_mask = rle_to_mask(rle, width=1600, height=256)\n",
        "\n",
        "                class_mask_resized = cv2.resize(class_mask, (self.img_w, self.img_h))\n",
        "                mask[...,idm] = class_mask_resized\n",
        "\n",
        "            X[idx,] = np.expand_dims(image_resized, axis=2)\n",
        "            y[idx,] = mask\n",
        "\n",
        "        # normalize Y\n",
        "        y = (y > 0).astype(int)\n",
        "\n",
        "        return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "1h91cQtTG45l"
      },
      "cell_type": "code",
      "source": [
        "# create a dict of all the masks\n",
        "masks = {}\n",
        "for index, row in train_df[train_df['EncodedPixels']!=-1].iterrows():\n",
        "    masks[row['ImageId_ClassId']] = row['EncodedPixels']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "mNjbUAL6G45l"
      },
      "cell_type": "code",
      "source": [
        "# repeat low represented samples more frequently to balance our dataset\n",
        "if repeat:\n",
        "    class_1_img_id = train_df[(train_df['EncodedPixels']!=-1) & (train_df['ClassId']=='1')]['ImageId'].values\n",
        "    class_1_img_id = np.repeat(class_1_img_id, class_1_repeat)\n",
        "    class_2_img_id = train_df[(train_df['EncodedPixels']!=-1) & (train_df['ClassId']=='2')]['ImageId'].values\n",
        "    class_2_img_id = np.repeat(class_2_img_id, class_2_repeat)\n",
        "    class_3_img_id = train_df[(train_df['EncodedPixels']!=-1) & (train_df['ClassId']=='3')]['ImageId'].values\n",
        "    class_3_img_id = np.repeat(class_3_img_id, class_3_repeat)\n",
        "    class_4_img_id = train_df[(train_df['EncodedPixels']!=-1) & (train_df['ClassId']=='4')]['ImageId'].values\n",
        "    class_4_img_id = np.repeat(class_4_img_id, class_4_repeat)\n",
        "    train_image_ids = np.concatenate([class_1_img_id, class_2_img_id, class_3_img_id, class_4_img_id])\n",
        "else:\n",
        "    # split the training data into train and validation set (stratified)\n",
        "    train_image_ids = train_df['ImageId'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "O31KkehkG45m"
      },
      "cell_type": "code",
      "source": [
        "X_train, X_val = train_test_split(train_image_ids, test_size=val_size, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ZdddBZBvG45m"
      },
      "cell_type": "code",
      "source": [
        "params = {'img_h': img_h,\n",
        "          'img_w': img_w,\n",
        "          'image_dir': train_image_dir,\n",
        "          'batch_size': batch_size,\n",
        "          'shuffle': True}\n",
        "\n",
        "# Get Generators\n",
        "training_generator = DataGenerator(X_train, masks, **params)\n",
        "validation_generator = DataGenerator(X_val, masks, **params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "VC8Bx0-XG45m"
      },
      "cell_type": "code",
      "source": [
        "# check out the shapes\n",
        "x, y = training_generator.__getitem__(0)\n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "KPJnl9iMG45m"
      },
      "cell_type": "code",
      "source": [
        "# visualize steel image with four classes of faults in seperate columns\n",
        "def viz_steel_img_mask(img, masks):\n",
        "    img = cv2.cvtColor(img.astype('float32'), cv2.COLOR_BGR2RGB)\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=4, sharey=True, figsize=(20,10))\n",
        "    cmaps = [\"Reds\", \"Blues\", \"Greens\", \"Purples\"]\n",
        "    for idx, mask in enumerate(masks):\n",
        "        ax[idx].imshow(img)\n",
        "        ax[idx].imshow(mask, alpha=0.3, cmap=cmaps[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "2RkaRwCWG45m"
      },
      "cell_type": "code",
      "source": [
        "# lets visualize some images with their faults to make sure our data generator is working like it should\n",
        "for ix in range(0,batch_size):\n",
        "    if y[ix].sum() > 0:\n",
        "        img = x[ix]\n",
        "        masks_temp = [y[ix][...,i] for i in range(0,4)]\n",
        "        viz_steel_img_mask(img, masks_temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GGPRocK0G45m"
      },
      "cell_type": "markdown",
      "source": [
        "## Resunet\n",
        "\n",
        "In this section we will define the building blocks for our network and train our network."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "mbcn5sj6G45n"
      },
      "cell_type": "code",
      "source": [
        "def bn_act(x, act=True):\n",
        "    'batch normalization layer with an optinal activation layer'\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    if act == True:\n",
        "        x = tf.keras.layers.Activation('relu')(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ORi11wcNG45n"
      },
      "cell_type": "code",
      "source": [
        "def conv_block(x, filters, kernel_size=3, padding='same', strides=1):\n",
        "    'convolutional layer which always uses the batch normalization layer'\n",
        "    conv = bn_act(x)\n",
        "    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n",
        "    return conv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "sQilt7xoG45n"
      },
      "cell_type": "code",
      "source": [
        "def stem(x, filters, kernel_size=3, padding='same', strides=1):\n",
        "    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
        "    conv = conv_block(conv, filters, kernel_size, padding, strides)\n",
        "    shortcut = Conv2D(filters, kernel_size=1, padding=padding, strides=strides)(x)\n",
        "    shortcut = bn_act(shortcut, act=False)\n",
        "    output = Add()([conv, shortcut])\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "5Gf8c_v7G45n"
      },
      "cell_type": "code",
      "source": [
        "def residual_block(x, filters, kernel_size=3, padding='same', strides=1):\n",
        "    res = conv_block(x, filters, k_size, padding, strides)\n",
        "    res = conv_block(res, filters, k_size, padding, 1)\n",
        "    shortcut = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
        "    shortcut = bn_act(shortcut, act=False)\n",
        "    output = Add()([shortcut, res])\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "vd-ZcWm4G45n"
      },
      "cell_type": "code",
      "source": [
        "def upsample_concat_block(x, xskip):\n",
        "    u = UpSampling2D((2,2))(x)\n",
        "    c = Concatenate()([u, xskip])\n",
        "    return c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "-WS4hm4mG45n"
      },
      "cell_type": "code",
      "source": [
        "def ResUNet(img_h, img_w):\n",
        "    f = [16, 32, 64, 128, 256]\n",
        "    inputs = Input((img_h, img_w, 1))\n",
        "\n",
        "    ## Encoder\n",
        "    e0 = inputs\n",
        "    e1 = stem(e0, f[0])\n",
        "    e2 = residual_block(e1, f[1], strides=2)\n",
        "    e3 = residual_block(e2, f[2], strides=2)\n",
        "    e4 = residual_block(e3, f[3], strides=2)\n",
        "    e5 = residual_block(e4, f[4], strides=2)\n",
        "\n",
        "    ## Bridge\n",
        "    b0 = conv_block(e5, f[4], strides=1)\n",
        "    b1 = conv_block(b0, f[4], strides=1)\n",
        "\n",
        "    ## Decoder\n",
        "    u1 = upsample_concat_block(b1, e4)\n",
        "    d1 = residual_block(u1, f[4])\n",
        "\n",
        "    u2 = upsample_concat_block(d1, e3)\n",
        "    d2 = residual_block(u2, f[3])\n",
        "\n",
        "    u3 = upsample_concat_block(d2, e2)\n",
        "    d3 = residual_block(u3, f[2])\n",
        "\n",
        "    u4 = upsample_concat_block(d3, e1)\n",
        "    d4 = residual_block(u4, f[1])\n",
        "\n",
        "    outputs = tf.keras.layers.Conv2D(4, (1, 1), padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "    model = tf.keras.models.Model(inputs, outputs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RvEEYFZTG45n"
      },
      "cell_type": "markdown",
      "source": [
        "## Loss Functions\n",
        "\n",
        "As our classes are highly imbalanced and we are stacking four output layers at once, it is even more important to get the loss function right. Here I will aggregate important loss functions so you can reuse and experiment with them along with me."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "UVfmXPidG45o"
      },
      "cell_type": "code",
      "source": [
        "# Dice similarity coefficient loss, brought to you by: https://github.com/nabsabraham/focal-tversky-unet\n",
        "def dsc(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = Flatten()(y_true)\n",
        "    y_pred_f = Flatten()(y_pred)\n",
        "    intersection = reduce_sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (reduce_sum(y_true_f) + reduce_sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dsc(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "13mezcLgG45o"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def tversky(y_true, y_pred, smooth=1e-6):\n",
        "    y_true_pos = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred_pos = tf.keras.layers.Flatten()(y_pred)\n",
        "    true_pos = tf.reduce_sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = tf.reduce_sum(y_true_pos * (1-y_pred_pos))\n",
        "    false_pos = tf.reduce_sum((1-y_true_pos)*y_pred_pos)\n",
        "    alpha = 0.7\n",
        "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
        "\n",
        "def tversky_loss(y_true, y_pred):\n",
        "    return 1 - tversky(y_true,y_pred)\n",
        "\n",
        "def focal_tversky_loss(y_true,y_pred):\n",
        "    pt_1 = tversky(y_true, y_pred)\n",
        "    gamma = 0.75\n",
        "    return tf.keras.backend.pow((1-pt_1), gamma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a8AwzeesG45o"
      },
      "cell_type": "markdown",
      "source": [
        "## Compile & Fit The Model"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "GV-ZPUy-G45o"
      },
      "cell_type": "code",
      "source": [
        "model = ResUNet(img_h=img_h, img_w=img_w)\n",
        "adam = tf.keras.optimizers.Adam(lr = 0.05, epsilon = 0.1)\n",
        "model.compile(optimizer=adam, loss=focal_tversky_loss, metrics=[tversky])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ezaDawT5G45o"
      },
      "cell_type": "code",
      "source": [
        "if load_pretrained_model:\n",
        "    try:\n",
        "        model.load_weights(pretrained_model_path)\n",
        "        print('pre-trained model loaded!')\n",
        "    except OSError:\n",
        "        print('You need to run the model and load the trained model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "a2dROiMsG45o"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(generator=training_generator, validation_data=validation_generator, epochs=epochs, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "bAQ2FTY4G45p"
      },
      "cell_type": "code",
      "source": [
        "if save_model:\n",
        "    model.save(model_save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U1FOUFBwG45t"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Insights\n",
        "\n",
        "In this section we take a look at the performance of our model and visually inspect how our predictions look like."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "Kd076zXTG45t"
      },
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['tversky'])\n",
        "plt.plot(history.history['val_tversky'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "\n",
        "# summarize history for loss\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Wt5TGupBG45u"
      },
      "cell_type": "code",
      "source": [
        "# a function to plot image with mask and image with predicted mask next to each other\n",
        "def viz_single_fault(img, mask, pred, image_class):\n",
        "\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(15,5))\n",
        "\n",
        "    cmaps = [\"Reds\", \"Blues\", \"Greens\", \"Purples\"]\n",
        "\n",
        "    ax[0].imshow(img)\n",
        "    ax[0].imshow(mask, alpha=0.3, cmap=cmaps[image_class-1])\n",
        "    ax[0].set_title('Mask - Defect Class %s' % image_class)\n",
        "\n",
        "    ax[1].imshow(img)\n",
        "    ax[1].imshow(pred, alpha=0.3, cmap=cmaps[image_class-1])\n",
        "    ax[1].set_title('Predicted Mask - Defect Class %s' % image_class)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HILzO05jG45u"
      },
      "cell_type": "markdown",
      "source": [
        "To get a better understanding of our model we will calculate the IoU score. If you are unfamiliar with the concept of IoU, you can read more of it here: http://ronny.rest/tutorials/module/localization_001/iou/."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "oAVPzqfYG45u"
      },
      "cell_type": "code",
      "source": [
        "# https://www.jeremyjordan.me/evaluating-image-segmentation-models/\n",
        "def calculate_iou(target, prediction):\n",
        "    intersection = np.logical_and(target, prediction)\n",
        "    union = np.logical_or(target, prediction)\n",
        "    if np.sum(union) == 0:\n",
        "        iou_score = 0\n",
        "    else:\n",
        "        iou_score = np.sum(intersection) / np.sum(union)\n",
        "    return iou_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "XnZlLHouG45u"
      },
      "cell_type": "code",
      "source": [
        "if make_submission == False:\n",
        "    # lets loop over the predictions and print 5 of each image cases with defects\n",
        "    count = 0\n",
        "    # a list to keep count of the number of plots made per image class\n",
        "    class_viz_count = [0,0,0,0]\n",
        "    # to keep the total iou score per image class\n",
        "    class_iou_score = [0, 0, 0, 0]\n",
        "    # to keep sum of mask pixels per image class\n",
        "    class_mask_sum = [0, 0, 0, 0]\n",
        "    # to keep sum of predicted mask pixels per image class\n",
        "    class_pred_sum = [0, 0, 0, 0]\n",
        "\n",
        "    # loop over to all the batches in one epoch\n",
        "    for i in range(0, validation_generator.__len__()):\n",
        "        # get a batch of image, true mask, and predicted mask\n",
        "        x, y = validation_generator.__getitem__(i)\n",
        "        predictions = model.predict(x)\n",
        "\n",
        "        # loop through x to get all the images in the batch\n",
        "        for idx, val in enumerate(x):\n",
        "            # we are only interested if there is a fault. if we are dropping images with no faults before this will become redundant\n",
        "            if y[idx].sum() > 0:\n",
        "                # get an image and convert to make it matplotlib.pyplot friendly\n",
        "                img = x[idx]\n",
        "                img = cv2.cvtColor(img.astype('float32'), cv2.COLOR_BGR2RGB)\n",
        "                # loop over the four ourput layers to create a list of all the masks for this image\n",
        "                masks_temp = [y[idx][...,i] for i in range(0,4)]\n",
        "                # loop over the four output layers to create a list of all the predictions for this image\n",
        "                preds_temp = [predictions[idx][...,i] for i in range(0,4)]\n",
        "                # turn to binary (prediction) mask\n",
        "                preds_temp = [p > .5 for p in preds_temp]\n",
        "\n",
        "                for i, (mask, pred) in enumerate(zip(masks_temp, preds_temp)):\n",
        "                    image_class = i + 1\n",
        "                    class_iou_score[i] += calculate_iou(mask, pred)\n",
        "                    class_mask_sum[i] += mask.sum()\n",
        "                    class_pred_sum[i] += pred.sum()\n",
        "                    if mask.sum() > 0 and class_viz_count[i] < 5:\n",
        "                        viz_single_fault(img, mask, pred, image_class)\n",
        "                        class_viz_count[i] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4RKWrzJgG45u"
      },
      "cell_type": "markdown",
      "source": [
        "Visualize the IoU, Sum of pixel for mask given, and sum of pixel for the prediction to better understand the performance of our model."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "NChUEhndG45v"
      },
      "cell_type": "code",
      "source": [
        " if make_submission == False:\n",
        "    class_ids = [1,2,3,4]\n",
        "    plt.figure(figsize=(20,5))\n",
        "    plt.subplot(1,3,1)\n",
        "    y_pos = np.arange(len(class_ids))\n",
        "    plt.bar(y_pos, class_iou_score)\n",
        "    plt.xticks(y_pos, class_ids)\n",
        "    plt.title('IoU score per class')\n",
        "    plt.ylabel('IoU Sum')\n",
        "    plt.xlabel('class id')\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.bar(y_pos, class_mask_sum)\n",
        "    plt.xticks(y_pos, class_ids)\n",
        "    plt.title('labeled mask pixel sum per class')\n",
        "    plt.ylabel('pixel sum')\n",
        "    plt.xlabel('class id')\n",
        "    plt.ticklabel_format(axis='y',style='sci',scilimits=(1,4))\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.bar(y_pos, class_pred_sum)\n",
        "    plt.xticks(y_pos, class_ids)\n",
        "    plt.title('predicted mask pixel sum per class')\n",
        "    plt.ylabel(' pixel sum')\n",
        "    plt.xlabel('class id')\n",
        "    plt.ticklabel_format(axis='y',style='sci',scilimits=(1,4))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3N1iqftVG45v"
      },
      "cell_type": "markdown",
      "source": [
        "Its obviously and unfortunately clear that we don't see enough sample of the other classes so we don't make a any prediction on them. I do wish we made some prediciton on class 4 but oh well, life building AI isn't easy =("
      ]
    },
    {
      "metadata": {
        "id": "H4CTz6u6G45v"
      },
      "cell_type": "markdown",
      "source": [
        "## Making Predictions & Submission File\n",
        "\n",
        "Now that our model is trained lets make a submission and file it in!"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "xBuelTRdG45v"
      },
      "cell_type": "code",
      "source": [
        "# return tensor in the right shape for prediction\n",
        "def get_test_tensor(img_dir, img_h, img_w, channels=1):\n",
        "\n",
        "    X = np.empty((1, img_h, img_w, channels))\n",
        "    # Store sample\n",
        "    image = cv2.imread(img_dir, 0)\n",
        "    image_resized = cv2.resize(image, (img_w, img_h))\n",
        "    image_resized = np.array(image_resized, dtype=np.float64)\n",
        "    # normalize image\n",
        "    image_resized -= image_resized.mean()\n",
        "    image_resized /= image_resized.std()\n",
        "\n",
        "    X[0,] = np.expand_dims(image_resized, axis=2)\n",
        "\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "YItxouPLG45v"
      },
      "cell_type": "code",
      "source": [
        "# this is an awesome little function to remove small spots in our predictions\n",
        "\n",
        "from skimage import morphology\n",
        "\n",
        "def remove_small_regions(img, size):\n",
        "    \"\"\"Morphologically removes small (less than size) connected regions of 0s or 1s.\"\"\"\n",
        "    img = morphology.remove_small_objects(img, size)\n",
        "    img = morphology.remove_small_holes(img, size)\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "CmWSLLTjG45z"
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "# get all files using glob\n",
        "test_files = [f for f in glob.glob('../input/severstal-steel-defect-detection/test_images/' + \"*.jpg\", recursive=True)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "wunG7YGDG45z"
      },
      "cell_type": "code",
      "source": [
        "submission = []\n",
        "\n",
        "# a function to apply all the processing steps necessery to each of the individual masks\n",
        "def process_pred_mask(pred_mask):\n",
        "\n",
        "    pred_mask = cv2.resize(pred_mask.astype('float32'),(1600, 256))\n",
        "    pred_mask = (pred_mask > .5).astype(int)\n",
        "    pred_mask = remove_small_regions(pred_mask, 0.02 * np.prod(512)) * 255\n",
        "    pred_mask = mask_to_rle(pred_mask)\n",
        "\n",
        "    return pred_mask\n",
        "\n",
        "# loop over all the test images\n",
        "for f in test_files:\n",
        "    # get test tensor, output is in shape: (1, 256, 512, 3)\n",
        "    test = get_test_tensor(f, img_h, img_w)\n",
        "    # get prediction, output is in shape: (1, 256, 512, 4)\n",
        "    pred_masks = model.predict(test)\n",
        "    # get a list of masks with shape: 256, 512\n",
        "    pred_masks = [pred_masks[0][...,i] for i in range(0,4)]\n",
        "    # apply all the processing steps to each of the mask\n",
        "    pred_masks = [process_pred_mask(pred_mask) for pred_mask in pred_masks]\n",
        "    # get our image id\n",
        "    id = f.split('/')[-1]\n",
        "    # create ImageId_ClassId and get the EncodedPixels for the class ID, and append to our submissions list\n",
        "    [submission.append((id+'_%s' % (k+1), pred_mask)) for k, pred_mask in enumerate(pred_masks)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "8xdheFB2G45z"
      },
      "cell_type": "code",
      "source": [
        "# convert to a csv\n",
        "submission_df = pd.DataFrame(submission, columns=['ImageId_ClassId', 'EncodedPixels'])\n",
        "# check out some predictions and see if RLE looks ok\n",
        "submission_df[ submission_df['EncodedPixels'] != ''].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "RW_99xcPG45z"
      },
      "cell_type": "code",
      "source": [
        "# take a look at our submission\n",
        "submission_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "2_--SmAHG450"
      },
      "cell_type": "code",
      "source": [
        "# write it out\n",
        "submission_df.to_csv('./submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8KelOtcKG450"
      },
      "cell_type": "markdown",
      "source": [
        "Okay guys! This is just a start and hopefully a good start. I will be back soon with update to make this much more professional. For EDA, check out my other Kernel for this competition [Mask of Steel - EDA & FP Mining](https://www.kaggle.com/ekhtiar/mask-of-steel-eda-fp-mining).\n",
        "\n",
        "**If you like my work please upvote this Kernel. This encourages or motivates people like me, who contributes to Kaggle on their own time with the intention to share knowledge, to continue the effort. Furthermore, if I made a mistake or can do something more, please leave a comment in the comments section to help me out. Many thanks in advance!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": " ResUNet-a Baseline on TensorFlow",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}